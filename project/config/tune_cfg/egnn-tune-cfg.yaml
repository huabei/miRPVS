# ray tune config
# scientific hyperparameter tuning

scientific_hyperparameter: ~
  # model
  # pl_module.model.hidden_nf:
  #   type: grid_search
  #   values: [64, 128, 256]
  # pl_module.model.n_layers:
  #   type: grid_search
  #   values: [2, 4, 6, 8]
  # pl_module.model.out_layers:
  #   type: grid_search
  #   values: [4, 6, 8]

nuissance_hyperparameter:
  # training
  pl_module.model.hidden_nf:
    type: choice
    categories: [64, 128]
  pl_module.model.n_layers:
    type: choice
    categories: [2, 4, 6, 8]
  pl_module.lr:
    type: loguniform
    lower: 1.e-5
    upper: 1.e-3
  pl_module.lr_decay_steps:
    type: choice
    categories: [5, 10, 20]
  pl_module.lr_decay_rate:
    type: choice
    categories: [0.9, 0.95, 0.99]
  pl_module.lr_decay_min_lr:
    type: loguniform
    lower: 1.e-6
    upper: 1.e-4
  pl_module.weight_decay:
    type: loguniform
    lower: 1.e-7
    upper: 1.e-4
  
fixed_hyperparameter:
  # project
  num_samples: 64
  grace_period: 10
  gpus_per_trial: 0.5
  project: egnn_tune
  comment: egnn tune choose model
  group: 验证independent attention的性能
  tune: True
  seed: 1234
  # wandb: False
  early_stop:
    monitor: val_loss
    patience: 10

  # trainer
  trainer:
    accelerator: gpu
    devices: 1
    fast_dev_run: False
    max_epochs: 80
    resume_from_checkpoint: ~
    auto_lr_find: False
    auto_scale_batch_size: False
    enable_progress_bar: False
    enable_model_summary: False
    enable_checkpointing: False

  # data
  pl_data_module:
    dataset: 'zinc_complex3a6p_data'
    data_dir: 'data/3a6p/zinc_drug_like_100k/3a6p_pocket5_202020'
    batch_size: 128
    num_workers: 8

  # model
  pl_module:
    loss: 'smooth_l1'
    model_name: 'egnn_independent_attention'
    lr_scheduler: 'cosine'

    model:
      in_node_nf: 10
      out_node_nf: 1
      attention: True
