
# checkpoint
#load_dir: checkpoints/gcn
# lr
lr_scheduler: cosine
lr_decay_steps: 5
lr: 0.001
lr_decay_min_lr: 1e-5
lr_decay_rate: 0.9

# data
dataset: zinc_complex3a6p_data_e3nn_subgraph
data_dir: 'data/3a6p/zinc_drug_like_100k/3a6p_pocket5_202020'
log_dir: 'log/e3nn_transformer_data_e3nn_pretrain'
model_name: molecular_e3nn_transformer_update

# train
max_epochs: 1
batch_size: 1024
gpus: 1
project: et_pretrain
in_channels: 128
hidden_channels: 128
out_channels: 1
hidden_layers: 8
out_layers: 3
loss: cross_entropy
accumulate_grad_batches: 2
# gradient_clip_val: 0.5

# comment
comment: 'e3nn pretrain'
