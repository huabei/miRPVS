{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "from model.origgnn import MolecularGNN, LigandDataset, pad_data\n",
    "from utils.package import plot_fit_confidence_bond\n",
    "from pytorch_lightning import Trainer\n",
    "import pytorch_lightning as pl\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch\n",
    "import numpy as np\n",
    "import wandb\n",
    "import time\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(hparams):\n",
    "\n",
    "    project = '3dgnn'\n",
    "    wandb.login(key='local-8fe6e6b5840c4c05aaaf6aac5ca8c1fb58abbd1f', host='http://localhost:8080')\n",
    "    wandb.init(project=project, save_code=True)\n",
    "\n",
    "    model_name = f'3dgnn-dim-{hparams.dim}-hlayer-{hparams.layer_hidden}-olayer-{hparams.layer_output}-' + time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "    dict_args = vars(hparams)\n",
    "    model = MolecularGNN(**dict_args)\n",
    "    # logger\n",
    "    wandb_logger = pl.loggers.WandbLogger()\n",
    "    # callbacks\n",
    "    # early stopping\n",
    "    early_stopping = pl.callbacks.early_stopping.EarlyStopping(monitor='val_loss', patience=20, mode='min')\n",
    "    # checkpoint\n",
    "    checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor='val_loss', mode='min', save_last=True,\n",
    "                                                         dirpath='output/model_path', filename=model_name)\n",
    "    if hparams.checkpoint == None:\n",
    "        trainer = Trainer.from_argparse_args(hparams, logger=wandb_logger, auto_lr_find=True, callbacks=[early_stopping, checkpoint_callback])\n",
    "    else:\n",
    "        trainer = Trainer(resume_from_checkpoint=hparams.checkpoint, callbacks=[early_stopping])\n",
    "    # trainer.tune(model)\n",
    "    # manage data\n",
    "    elements_dict = defaultdict(lambda: len(elements_dict))\n",
    "    dataset = LigandDataset(hparams.data_path, elements_dict)\n",
    "    train_size = int(len(dataset)*0.8)\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, len(dataset) - train_size], generator=torch.Generator().manual_seed(42))\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=hparams.batch_size, collate_fn=pad_data, num_workers=10)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=hparams.batch_size, collate_fn=pad_data, num_workers=10)\n",
    "    # Train\n",
    "    trainer.fit(model, train_dataloader, val_dataloader)\n",
    "    # trainer.save_checkpoint(time.strftime(\"%Y%m%d_%H%M%S\", time.localtime()) + \".ckpt\")\n",
    "    trainer.test(model, val_dataloader, verbose=False)\n",
    "    x = np.array(model.predictions['true'])\n",
    "    y = np.array(model.predictions['pred'])\n",
    "    val_r2 = r2_score(x, y)\n",
    "    val_fig = plot_fit_confidence_bond(x, y, val_r2, annot=False)\n",
    "    \n",
    "    model.predictions = defaultdict(list)\n",
    "    trainer.test(model, dataloaders=train_dataloader, verbose=False)\n",
    "    x = np.array(model.predictions['true'])\n",
    "    y = np.array(model.predictions['pred'])\n",
    "    train_r2 = r2_score(x, y)\n",
    "    train_fig = plot_fit_confidence_bond(x, y, train_r2, annot=False)\n",
    "    wandb.log({'train_res': train_fig, 'val_res': val_fig})\n",
    "    # print(val_r2)\n",
    "    # model.log('val_r2', val_r2)\n",
    "    wandb.log({'val_r2': val_r2, 'train_r2':train_r2})\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument(\"--dim\", type=int, default=512)\n",
    "    parser.add_argument(\"--layer_hidden\",type=int, default=30)\n",
    "    parser.add_argument(\"--layer_output\",type=int, default=8)\n",
    "    parser.add_argument(\"--batch_size\",type=int, default=128)\n",
    "    parser.add_argument(\"--data_path\",type=str, default=None)\n",
    "    parser.add_argument(\"--checkpoint\",type=str, default=None)\n",
    "    dataset_path = '/home/huabei/Projects/molecularGNN_3Dstructure/dataset/dock_conformation_1/exhaus_96/data_train.txt'\n",
    "    checkpoint = '20220618_211314.ckpt'\n",
    "    # add model args\n",
    "    parser = MolecularGNN.add_model_specific_args(parent_parser=parser)\n",
    "    # add Trainer args\n",
    "    parser = Trainer.add_argparse_args(parser)\n",
    "    args = parser.parse_args(['--data_path', dataset_path, '--learning_rate', '0.0001', '--gpus=1', '--max_epochs', '1000'])\n",
    "\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
