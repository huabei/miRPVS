{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "from model.origgnn import MolecularGNN\n",
    "from utils.package import plot_fit_confidence_bond\n",
    "from pytorch_lightning import Trainer\n",
    "import pytorch_lightning as pl\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch\n",
    "import numpy as np\n",
    "import wandb\n",
    "import time\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhuabei\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for localhost to your netrc file: /home/huabei/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "wandb.login(key='local-8fe6e6b5840c4c05aaaf6aac5ca8c1fb58abbd1f', host='http://localhost:8080')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%wandb\n",
    "def main(hparams):\n",
    "    \n",
    "    model_name = f'3dgnn-dim-{hparams.dim}-hlayer-{hparams.layer_hidden}-olayer-{hparams.layer_output}-' + time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "    dict_args = vars(hparams)\n",
    "    model = MolecularGNN(**dict_args)\n",
    "    # logger\n",
    "    wandb_logger = pl.loggers.WandbLogger(save_dir='log/origgnn')\n",
    "    # callbacks\n",
    "    # early stopping\n",
    "    early_stopping = pl.callbacks.early_stopping.EarlyStopping(monitor='val_loss', patience=20, mode='min')\n",
    "    # checkpoint\n",
    "    checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor='val_loss', mode='min', save_last=True,\n",
    "                                                         dirpath='checkpoints', filename=model_name)\n",
    "    if hparams.checkpoint == None:\n",
    "        trainer = Trainer.from_argparse_args(hparams, logger=wandb_logger, auto_lr_find=True, callbacks=[early_stopping, checkpoint_callback])\n",
    "    else:\n",
    "        trainer = Trainer(resume_from_checkpoint=hparams.checkpoint, callbacks=[early_stopping])\n",
    "    # trainer.tune(model)\n",
    " \n",
    "    # Train\n",
    "    trainer.fit(model)\n",
    "    # trainer.save_checkpoint(time.strftime(\"%Y%m%d_%H%M%S\", time.localtime()) + \".ckpt\")\n",
    "    trainer.test(model, dataloaders=model.val_dataloader(), verbose=False)\n",
    "    x = np.array(model.predictions['true'])\n",
    "    y = np.array(model.predictions['pred'])\n",
    "    val_r2 = r2_score(x, y)\n",
    "    val_fig = plot_fit_confidence_bond(x, y, val_r2, annot=False)\n",
    "    \n",
    "    model.predictions = defaultdict(list)\n",
    "    trainer.test(model, dataloaders=model.train_dataloader(), verbose=False)\n",
    "    x = np.array(model.predictions['true'])\n",
    "    y = np.array(model.predictions['pred'])\n",
    "    train_r2 = r2_score(x, y)\n",
    "    train_fig = plot_fit_confidence_bond(x, y, train_r2, annot=False)\n",
    "    if True:\n",
    "        wandb.log({'train_res': train_fig, 'val_res': val_fig})\n",
    "        wandb.log({'val_r2': val_r2, 'train_r2':train_r2})\n",
    "        wandb.finish()\n",
    "\n",
    "def prepare_arg():\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument(\"--dim\", type=int, default=512)\n",
    "    parser.add_argument(\"--layer_hidden\",type=int, default=24)\n",
    "    parser.add_argument(\"--layer_output\",type=int, default=8)\n",
    "    parser.add_argument(\"--batch_size\",type=int, default=128)\n",
    "    parser.add_argument(\"--data_path\",type=str, default=None)\n",
    "    parser.add_argument(\"--checkpoint\",type=str, default=None)\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    project = '3dgnn'\n",
    "    wandb.init(project=project, dir='log/origgnn')\n",
    "    # prepare args\n",
    "    parser = prepare_arg()\n",
    "    dataset_path = '/home/huabei/Projects/SMTarRNA/project/data/in_man_exhaustiveness_96_orig_conformation.txt'\n",
    "    checkpoint = '20220618_211314.ckpt'\n",
    "    # add model args\n",
    "    parser = MolecularGNN.add_model_specific_args(parent_parser=parser)\n",
    "    # add Trainer args\n",
    "    parser = Trainer.add_argparse_args(parser)\n",
    "    args = parser.parse_args(['--data_path', dataset_path, '--learning_rate', '0.0001', '--gpus=1', '--max_epochs', '1000'])\n",
    "\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wandb sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: t9aqqtww\n",
      "Sweep URL: http://localhost:8080/huabei/origgnn_sweep/sweeps/t9aqqtww\n"
     ]
    }
   ],
   "source": [
    "sweep_config = {\n",
    "  \"name\" : \"sweep\",\n",
    "  \"method\" : \"random\",\n",
    "  \"parameters\": {\n",
    "    \"epochs\": {\n",
    "      \"value\": 500\n",
    "    },\n",
    "    \"learning_rate\": {\n",
    "      \"distribution\": \"log_uniform_values\",\n",
    "      \"min\": 0.00001,\n",
    "      \"max\": 0.1\n",
    "    },\n",
    "    \"lr_decay\": {\n",
    "      \"min\": 0.95,\n",
    "      \"max\": 0.999\n",
    "    },\n",
    "    \"dim\" : {\n",
    "      \"distribution\": \"int_uniform\",\n",
    "      \"min\": 128,\n",
    "      \"max\": 512\n",
    "    },\n",
    "    \"layer_hidden\": {\n",
    "      \"distribution\": \"int_uniform\",\n",
    "      \"min\": 8,\n",
    "      \"max\": 32\n",
    "    },\n",
    "    \"layer_output\": {\n",
    "      \"distribution\": \"int_uniform\",\n",
    "      \"min\": 8,\n",
    "      \"max\": 20\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project='origgnn_sweep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arg_for_sweep(config: dict):\n",
    "    # prepare args\n",
    "    parser = prepare_arg()\n",
    "    dataset_path = '/home/huabei/Projects/SMTarRNA/project/data/in_man_exhaustiveness_96_orig_conformation.txt'\n",
    "    checkpoint = '20220618_211314.ckpt'\n",
    "    # add model args\n",
    "    parser = MolecularGNN.add_model_specific_args(parent_parser=parser)\n",
    "    # add Trainer args\n",
    "    parser = Trainer.add_argparse_args(parser)\n",
    "    hyperparameter_list = ['--data_path', dataset_path, '--gpus=1']\n",
    "    for key, value in config.items():\n",
    "        # print(key, value)\n",
    "        hyperparameter_list.extend(['--' + key, str(value)])\n",
    "    # print(hyperparameter_list)\n",
    "    args = parser.parse_args(hyperparameter_list)\n",
    "    # print('here is right')\n",
    "    return args\n",
    "    # args = parser.parse_args(['--data_path', dataset_path, '--learning_rate', '0.0001', '--gpus=1', '--max_epochs', '1000'])\n",
    "\n",
    "def train():\n",
    "    with wandb.init(dir='log/origgnn') as run:\n",
    "        config = wandb.config\n",
    "        args = arg_for_sweep(config=config)\n",
    "        # print(vars(args))\n",
    "        # print(config)\n",
    "        # main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0w9lznno with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 484\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_hidden: 23\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_output: 13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0010658098334630822\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>log/origgnn/wandb/run-20220621_211241-0w9lznno</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"http://localhost:8080/huabei/origgnn_sweep/runs/0w9lznno\" target=\"_blank\">floral-sweep-10</a></strong> to <a href=\"http://localhost:8080/huabei/origgnn_sweep\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"http://localhost:8080/huabei/origgnn_sweep/sweeps/t9aqqtww\" target=\"_blank\">http://localhost:8080/huabei/origgnn_sweep/sweeps/t9aqqtww</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim 484\n",
      "epochs 500\n",
      "layer_hidden 23\n",
      "layer_output 13\n",
      "learning_rate 0.0010658098334630822\n",
      "['--data_path', '/home/huabei/Projects/SMTarRNA/project/data/in_man_exhaustiveness_96_orig_conformation.txt', '--gpus=1', '--dim', 484, '--epochs', 500, '--layer_hidden', 23, '--layer_output', 13, '--learning_rate', 0.0010658098334630822]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415b3993268f4b598800c58c8abf1565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.048 MB of 0.048 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">floral-sweep-10</strong>: <a href=\"http://localhost:8080/huabei/origgnn_sweep/runs/0w9lznno\" target=\"_blank\">http://localhost:8080/huabei/origgnn_sweep/runs/0w9lznno</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>log/origgnn/wandb/run-20220621_211241-0w9lznno/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 0w9lznno errored: TypeError(\"'int' object is not subscriptable\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 0w9lznno errored: TypeError(\"'int' object is not subscriptable\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bqpdn6sk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 357\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_hidden: 26\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_output: 11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005298522584671892\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>log/origgnn/wandb/run-20220621_211251-bqpdn6sk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"http://localhost:8080/huabei/origgnn_sweep/runs/bqpdn6sk\" target=\"_blank\">trim-sweep-11</a></strong> to <a href=\"http://localhost:8080/huabei/origgnn_sweep\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"http://localhost:8080/huabei/origgnn_sweep/sweeps/t9aqqtww\" target=\"_blank\">http://localhost:8080/huabei/origgnn_sweep/sweeps/t9aqqtww</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim 357\n",
      "epochs 500\n",
      "layer_hidden 26\n",
      "layer_output 11\n",
      "learning_rate 0.0005298522584671892\n",
      "['--data_path', '/home/huabei/Projects/SMTarRNA/project/data/in_man_exhaustiveness_96_orig_conformation.txt', '--gpus=1', '--dim', 357, '--epochs', 500, '--layer_hidden', 26, '--layer_output', 11, '--learning_rate', 0.0005298522584671892]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0bf8fd66c040249ad49dfb79207a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.048 MB of 0.048 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">trim-sweep-11</strong>: <a href=\"http://localhost:8080/huabei/origgnn_sweep/runs/bqpdn6sk\" target=\"_blank\">http://localhost:8080/huabei/origgnn_sweep/runs/bqpdn6sk</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>log/origgnn/wandb/run-20220621_211251-bqpdn6sk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run bqpdn6sk errored: TypeError(\"'int' object is not subscriptable\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run bqpdn6sk errored: TypeError(\"'int' object is not subscriptable\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dru02rvo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 461\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_hidden: 29\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_output: 13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 8.877196129090286e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>log/origgnn/wandb/run-20220621_211301-dru02rvo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"http://localhost:8080/huabei/origgnn_sweep/runs/dru02rvo\" target=\"_blank\">wise-sweep-12</a></strong> to <a href=\"http://localhost:8080/huabei/origgnn_sweep\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"http://localhost:8080/huabei/origgnn_sweep/sweeps/t9aqqtww\" target=\"_blank\">http://localhost:8080/huabei/origgnn_sweep/sweeps/t9aqqtww</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim 461\n",
      "epochs 500\n",
      "layer_hidden 29\n",
      "layer_output 13\n",
      "learning_rate 8.877196129090286e-05\n",
      "['--data_path', '/home/huabei/Projects/SMTarRNA/project/data/in_man_exhaustiveness_96_orig_conformation.txt', '--gpus=1', '--dim', 461, '--epochs', 500, '--layer_hidden', 29, '--layer_output', 13, '--learning_rate', 8.877196129090286e-05]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79bc3868747440cbb2db06a66fea72d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.048 MB of 0.048 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">wise-sweep-12</strong>: <a href=\"http://localhost:8080/huabei/origgnn_sweep/runs/dru02rvo\" target=\"_blank\">http://localhost:8080/huabei/origgnn_sweep/runs/dru02rvo</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>log/origgnn/wandb/run-20220621_211301-dru02rvo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run dru02rvo errored: TypeError(\"'int' object is not subscriptable\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run dru02rvo errored: TypeError(\"'int' object is not subscriptable\")\n",
      "Detected 3 failed runs in the first 60 seconds, killing sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Detected 3 failed runs in the first 60 seconds, killing sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: To disable this check set WANDB_AGENT_DISABLE_FLAPPING=true\n"
     ]
    }
   ],
   "source": [
    "count = 1 # number of runs to execute\n",
    "wandb.agent(sweep_id, function=train, count=count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('smtr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a75462293d05fc3e00128f4985dd13fcf50f4f5144b1474848efbcac1f09cd24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
